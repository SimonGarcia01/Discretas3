{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31df2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35c03f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "657cedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unified data set\n",
    "df = pd.read_excel('raw_data.xlsx', sheet_name='raw_data', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69d0ad8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What a waste of money and time!.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  y\n",
       "0  So there is no way for me to plug it in here i...  0\n",
       "1                        Good case, Excellent value.  1\n",
       "2                             Great for the jawbone.  1\n",
       "3  Tied to charger for conversations lasting more...  0\n",
       "4                                  The mic is great.  1\n",
       "5  I have to jiggle the plug to get it to line up...  0\n",
       "6  If you have several dozen or several hundred c...  0\n",
       "7        If you are Razr owner...you must have this!  1\n",
       "8                Needless to say, I wasted my money.  0\n",
       "9                   What a waste of money and time!.  0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check it worked and that the columns have the names\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e333c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape to know if it matched the description of the data  (3000 rows)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5d78cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import th nltk libraries to process the text\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbe6a735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\n"
     ]
    }
   ],
   "source": [
    "#I want to see how each step changes the text (taken from the workshop that was assigned)\n",
    "#Just found a random line with text with various issues\n",
    "random_text = df.iloc[3,0]\n",
    "print(random_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bbb56da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tied to charger for conversations lasting more than 45 minutes MAJOR PROBLEMS  \n"
     ]
    }
   ],
   "source": [
    "# I did the suggest process for preprocessing but im adding two more steps\n",
    "\n",
    "#Before doing the suggested process I will be:\n",
    "# removing all punctuation (\"!\", \",\", \".\", \"?\", etc) replacing it with spaces.\n",
    "# Getting this from a case where minutes.major was stuck together.\n",
    "import re\n",
    "random_text = re.sub(r'[^\\w\\s]', ' ', random_text)\n",
    "\n",
    "print(random_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "520251c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tied to charger for conversations lasting more than 45 minutes MAJOR PROBLEMS\n"
     ]
    }
   ],
   "source": [
    "#Next get rid of all unnecesary spaces at either side and in between\n",
    "random_text = ' '.join(random_text.split())\n",
    "print(random_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8bcaeda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tied', 'to', 'charger', 'for', 'conversations', 'lasting', 'more', 'than', '45', 'minutes', 'MAJOR', 'PROBLEMS']\n"
     ]
    }
   ],
   "source": [
    "#Now we start the recommended process\n",
    "# First check what tokenization does\n",
    "tokens = word_tokenize(random_text)\n",
    "print(tokens)\n",
    "# Interestingly, things like minutes.Major are stuck together and ! are separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89083bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tied', 'to', 'charger', 'for', 'conversations', 'lasting', 'more', 'than', '45', 'minutes', 'major', 'problems']\n"
     ]
    }
   ],
   "source": [
    "# Now lets see the result of lowercasing\n",
    "tokens = [token.lower() for token in tokens]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "232eb6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tied', 'charger', 'conversations', 'lasting', '45', 'minutes', 'major', 'problems']\n"
     ]
    }
   ],
   "source": [
    "# Now we remove the stop words using the defined ones in nltk\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens = [token for token in tokens if token not in stop_words]\n",
    "print(tokens)\n",
    "# Cool! this removed transitive words like: to, for, more, than..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd590e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tied', 'charger', 'conversation', 'lasting', '45', 'minute', 'major', 'problem']\n"
     ]
    }
   ],
   "source": [
    "#According to the steps we must use the \"lemmatize\"\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "print(tokens)\n",
    "\n",
    "#This changed the plural to singular\n",
    "#Read this can change words to different versions if you consider them as verbs, adjectives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d16c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tied charger conversation lasting 45 minute major problem\n"
     ]
    }
   ],
   "source": [
    "#Finally paste the tokens back together\n",
    "back_together = ' '.join(tokens)\n",
    "print(back_together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46f57158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Repeate the Steps Outside\n",
    "\n",
    "    # 1. Remove all punctuation by replacing with spaces\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "\n",
    "    # 2. Normalize spaces\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    # 3. Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # 4. Lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    # 5. Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # 6. Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # 7. Join back into text\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c666014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>way plug u unless go converter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied charger conversation lasting 45 minute ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mic great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>think food flavor texture lacking</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>appetite instantly gone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>overall impressed would go back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>whole experience underwhelming think go ninja ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>wasted enough life poured salt wound drawing t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      x  y\n",
       "0                        way plug u unless go converter  0\n",
       "1                             good case excellent value  1\n",
       "2                                         great jawbone  1\n",
       "3     tied charger conversation lasting 45 minute ma...  0\n",
       "4                                             mic great  1\n",
       "...                                                 ... ..\n",
       "2995                  think food flavor texture lacking  0\n",
       "2996                            appetite instantly gone  0\n",
       "2997                    overall impressed would go back  0\n",
       "2998  whole experience underwhelming think go ninja ...  0\n",
       "2999  wasted enough life poured salt wound drawing t...  0\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now apply all changes to the actual data set.\n",
    "df['x'] = df['x'].apply(preprocess_text)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22ec5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"cleaned_data.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
